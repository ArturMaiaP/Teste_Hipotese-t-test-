---
title: "Comparing Social Jukebox Management Algorithms"
output:
  pdf_document: default
  df_print: paged
  html_document: null
theme: sandstone
---
## Author: Artur Maia Pereira
```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
theme_set(theme_bw())

library(boot)
library(broom)

knitr::opts_chunk$set(tidy = FALSE,
                      fig.width = 6,
                      fig.height = 5)

```
1. Brief description of the data set and a summary of its attributes

Social jukeboxes are systems that enable social music listening with listeners collaboratively choosing the music to be played. Naturally, because music tastes are diverse, using social jukeboxes often involves conflicting interests.

This data set presents user satisfaction data from the experiment with three groups of listeners and three conflict management mechanisms plus. They consider as baseline an experiment without conflict management algorithm. The mechanisms were chosen to represent those most commonly used in the state of the practice: like/dislike feedback, up/down voting of songs in a queue, and a skip feature. We can see the dataset attributes above. 

```{r read}
dados = read_csv(here::here("data/satisfacoes.csv"), 
                 col_types = "cdcc") 

glimpse(dados)
```

2. Initial plan for data exploration
<p> An analysis of this data set was proposed in http://ismir2015.uma.es/articles/212_Paper.pdf. Then, my initial plan is to replicate the paper experiments to validate their results. 

3. Actions taken for data cleaning and feature engineering

As I am reproducing a set of experiments, there is no need for data cleaning or adjustments in the data set.

4. Key Findings and Insights, which synthesizes the results of Exploratory Data Analysis in an insightful and actionable manner

In the following plot, we can see the data distribution considering the satisfaction attribute.
```{r}
dados = dados %>% arrange(scenario,satisfaction)
ggplot() + 
    geom_violin(data = dados, mapping = aes(x=scenario,y=satisfaction),alpha = 1,colour = "gray")+
    geom_jitter(data = dados,mapping = aes(colour= scenario, x=scenario,y=satisfaction),alpha = 0.5,size = 2,height = 0.05, width = 0.1, show.legend = FALSE)
```
```{r}
dados %>% group_by(scenario) %>% summarize(satisfaction_mean = mean(satisfaction)) %>% arrange(desc(satisfaction_mean))
```
Looking at the satisfaction mean and the plot, we note that the up/downvoting algorithm had better acceptance by the users. 

5.Formulating at least 3 hypothesis about this data


H0: There was a significant difference in the user satisfaction between the baseline social jukebox and the three social jukeboxes with conflict management algorithms.

H1: Social jukeboxes with conflict management presented better user satisfaction than the baseline social jukebox.

H2: Combine conflict management algorithms improved user satisfaction.

6. Conducting a formal significance test for one of the hypotheses and discuss the results.

Baseline x (Like/dislike, up/downvoting, combined)

Applying the Mann-Whitney test with the significance level of 0.05 we have:

```{r warning = FALSE}
comparacao1 = dados %>% 
    filter(scenario %in% c("baseline", "like/dislike"))
comparacao2 = dados %>% 
    filter(scenario %in% c("baseline", "up/downvoting"))
comparacao3 = dados %>% 
    filter(scenario %in% c("baseline", "combined"))
dif <- function(d) {
    
    wilcox.test(satisfaction ~ scenario,
            data=d)
}
dif(comparacao1)
dif(comparacao2)
dif(comparacao3)

```


As the three satisfaction algorithms had a p-value < 0.05, we can reject the null hypothesis (H0). It confirms that the user satisfaction for like/dislike, up/downvoting, and combined are significantly different from the baseline.


7. Suggestions for next steps in analyzing this data.

In a further step, we can perform an exploratory analysis of the satisfaction for each user group to obtain a fine-grained view. 


8. A paragraph that summarizes the quality of this data set and a request for additional data if needed.

The original analyses of this data set was published in the 16th International Society for Music Information Retrieval Conference(2015), being submitted to a peer-review process. This publication might be enough to validade the data set quality.


